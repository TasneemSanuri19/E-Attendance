{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is used to implement every component of the system on a lecture of 2 videos."
      ],
      "metadata": {
        "id": "_CpdGyrXBUDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i6oCHh1Qo_ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frame Extraction"
      ],
      "metadata": {
        "id": "_NXa4ioooQ8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import floor\n",
        "import cv2"
      ],
      "metadata": {
        "id": "EtMMTjto8CQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "frame extraction was done every minute to increase the number of testing instances"
      ],
      "metadata": {
        "id": "YrHvkhoOp0XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for i in range(2):\n",
        "  video = cv2.VideoCapture(f\"/content/drive/MyDrive/Deployment_Folders/DeploymentLecture/{i+1}.mp4\")\n",
        "  # count the number of frames \\ fps\n",
        "  frames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "  \n",
        "  # calculate duration of the video\n",
        "  seconds = floor(frames / fps)\n",
        "  mins = floor(seconds/60)\n",
        "\n",
        "  minutes = 1\n",
        "  seconds = 0\n",
        "  while minutes <= mins:\n",
        "    frame_id = int(fps*(minutes*60 + seconds))\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
        "    ret, frame = video.read()\n",
        "    #here put the path of the frames folder you created in your drive, and each time change the name of the video according to the video you have\n",
        "    cv2.imwrite(r'/content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid{}frame{}.png'.format(i+1,frame_id), frame)\n",
        "    minutes+=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3CP23ge6kGX",
        "outputId": "4484a475-9d9c-4c2b-a838-4e204f9165b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 57s, sys: 4.44 s, total: 3min 1s\n",
            "Wall time: 4min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detection"
      ],
      "metadata": {
        "id": "SK9tf-kwoh1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone \n",
        "!pip install -r /content/yolov5/requirements.txt  # install"
      ],
      "metadata": {
        "id": "oivXTPCpqf8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can put all the frames in one folder \n",
        "!python /content/yolov5/detect.py --weights /content/drive/MyDrive/Weights/Detection_Weights.pt --img 640 --conf 0.4 --source '/content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/*.png' --save-crop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZuJOdDZolPL",
        "outputId": "9adc346f-8725-46ee-96a4-3982931797d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/Weights/Detection_Weights.pt'], source=/content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/*.png, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.4, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 ðŸš€ v7.0-162-gc3e4e94 Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame10800.png: 384x640 26 faces, 41.1ms\n",
            "image 2/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame1200.png: 384x640 6 faces, 8.0ms\n",
            "image 3/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame12000.png: 384x640 27 faces, 8.0ms\n",
            "image 4/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame13200.png: 384x640 29 faces, 7.9ms\n",
            "image 5/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame14400.png: 384x640 28 faces, 7.9ms\n",
            "image 6/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame15600.png: 384x640 29 faces, 7.9ms\n",
            "image 7/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame16800.png: 384x640 29 faces, 7.9ms\n",
            "image 8/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame18000.png: 384x640 29 faces, 7.9ms\n",
            "image 9/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame19200.png: 384x640 32 faces, 7.9ms\n",
            "image 10/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame20400.png: 384x640 32 faces, 7.9ms\n",
            "image 11/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame21600.png: 384x640 29 faces, 7.9ms\n",
            "image 12/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame22800.png: 384x640 32 faces, 7.9ms\n",
            "image 13/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame2400.png: 384x640 9 faces, 7.9ms\n",
            "image 14/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame24000.png: 384x640 28 faces, 7.9ms\n",
            "image 15/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame25200.png: 384x640 31 faces, 7.9ms\n",
            "image 16/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame26400.png: 384x640 32 faces, 8.0ms\n",
            "image 17/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame27600.png: 384x640 28 faces, 7.9ms\n",
            "image 18/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame28800.png: 384x640 32 faces, 7.9ms\n",
            "image 19/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame30000.png: 384x640 28 faces, 7.9ms\n",
            "image 20/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame31200.png: 384x640 30 faces, 7.9ms\n",
            "image 21/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame32400.png: 384x640 30 faces, 7.9ms\n",
            "image 22/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame33600.png: 384x640 30 faces, 7.9ms\n",
            "image 23/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame34800.png: 384x640 30 faces, 8.0ms\n",
            "image 24/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame3600.png: 384x640 12 faces, 7.9ms\n",
            "image 25/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame36000.png: 384x640 30 faces, 7.9ms\n",
            "image 26/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame37200.png: 384x640 30 faces, 8.0ms\n",
            "image 27/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame38400.png: 384x640 28 faces, 7.9ms\n",
            "image 28/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame39600.png: 384x640 31 faces, 7.9ms\n",
            "image 29/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame40800.png: 384x640 31 faces, 7.9ms\n",
            "image 30/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame42000.png: 384x640 32 faces, 7.9ms\n",
            "image 31/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame43200.png: 384x640 30 faces, 7.9ms\n",
            "image 32/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame44400.png: 384x640 30 faces, 7.9ms\n",
            "image 33/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame45600.png: 384x640 30 faces, 7.9ms\n",
            "image 34/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame46800.png: 384x640 32 faces, 8.7ms\n",
            "image 35/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame4800.png: 384x640 15 faces, 7.9ms\n",
            "image 36/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame48000.png: 384x640 29 faces, 7.9ms\n",
            "image 37/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame49200.png: 384x640 31 faces, 8.0ms\n",
            "image 38/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame50400.png: 384x640 32 faces, 7.9ms\n",
            "image 39/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame51600.png: 384x640 30 faces, 8.0ms\n",
            "image 40/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame52800.png: 384x640 31 faces, 8.0ms\n",
            "image 41/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame54000.png: 384x640 32 faces, 8.0ms\n",
            "image 42/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame55200.png: 384x640 33 faces, 8.0ms\n",
            "image 43/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame56400.png: 384x640 31 faces, 8.5ms\n",
            "image 44/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame57600.png: 384x640 30 faces, 7.9ms\n",
            "image 45/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame58800.png: 384x640 33 faces, 7.9ms\n",
            "image 46/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame6000.png: 384x640 21 faces, 7.9ms\n",
            "image 47/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame60000.png: 384x640 32 faces, 7.9ms\n",
            "image 48/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame7200.png: 384x640 20 faces, 8.0ms\n",
            "image 49/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame8400.png: 384x640 23 faces, 7.9ms\n",
            "image 50/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid1frame9600.png: 384x640 24 faces, 7.9ms\n",
            "image 51/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame10800.png: 384x640 26 faces, 7.9ms\n",
            "image 52/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame1200.png: 384x640 4 faces, 7.9ms\n",
            "image 53/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame12000.png: 384x640 29 faces, 7.9ms\n",
            "image 54/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame13200.png: 384x640 28 faces, 7.9ms\n",
            "image 55/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame14400.png: 384x640 29 faces, 7.9ms\n",
            "image 56/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame15600.png: 384x640 29 faces, 7.9ms\n",
            "image 57/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame16800.png: 384x640 29 faces, 7.9ms\n",
            "image 58/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame18000.png: 384x640 36 faces, 7.9ms\n",
            "image 59/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame19200.png: 384x640 31 faces, 7.9ms\n",
            "image 60/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame20400.png: 384x640 36 faces, 7.9ms\n",
            "image 61/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame21600.png: 384x640 32 faces, 7.9ms\n",
            "image 62/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame22800.png: 384x640 31 faces, 8.2ms\n",
            "image 63/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame2400.png: 384x640 10 faces, 7.9ms\n",
            "image 64/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame24000.png: 384x640 34 faces, 7.9ms\n",
            "image 65/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame25200.png: 384x640 31 faces, 7.9ms\n",
            "image 66/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame26400.png: 384x640 32 faces, 7.9ms\n",
            "image 67/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame27600.png: 384x640 32 faces, 7.9ms\n",
            "image 68/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame28800.png: 384x640 32 faces, 7.9ms\n",
            "image 69/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame30000.png: 384x640 31 faces, 7.9ms\n",
            "image 70/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame31200.png: 384x640 32 faces, 7.9ms\n",
            "image 71/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame32400.png: 384x640 30 faces, 9.1ms\n",
            "image 72/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame33600.png: 384x640 31 faces, 7.9ms\n",
            "image 73/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame34800.png: 384x640 34 faces, 7.9ms\n",
            "image 74/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame3600.png: 384x640 11 faces, 7.9ms\n",
            "image 75/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame36000.png: 384x640 33 faces, 7.9ms\n",
            "image 76/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame37200.png: 384x640 31 faces, 7.9ms\n",
            "image 77/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame38400.png: 384x640 30 faces, 9.7ms\n",
            "image 78/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame39600.png: 384x640 30 faces, 8.0ms\n",
            "image 79/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame40800.png: 384x640 31 faces, 7.9ms\n",
            "image 80/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame42000.png: 384x640 33 faces, 8.3ms\n",
            "image 81/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame43200.png: 384x640 30 faces, 8.2ms\n",
            "image 82/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame44400.png: 384x640 33 faces, 7.9ms\n",
            "image 83/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame45600.png: 384x640 32 faces, 10.0ms\n",
            "image 84/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame46800.png: 384x640 33 faces, 7.9ms\n",
            "image 85/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame4800.png: 384x640 17 faces, 8.0ms\n",
            "image 86/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame48000.png: 384x640 31 faces, 9.0ms\n",
            "image 87/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame49200.png: 384x640 31 faces, 7.9ms\n",
            "image 88/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame50400.png: 384x640 32 faces, 7.9ms\n",
            "image 89/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame51600.png: 384x640 29 faces, 7.9ms\n",
            "image 90/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame52800.png: 384x640 32 faces, 7.9ms\n",
            "image 91/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame54000.png: 384x640 32 faces, 7.9ms\n",
            "image 92/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame55200.png: 384x640 30 faces, 7.9ms\n",
            "image 93/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame56400.png: 384x640 30 faces, 7.9ms\n",
            "image 94/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame57600.png: 384x640 28 faces, 7.9ms\n",
            "image 95/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame6000.png: 384x640 20 faces, 8.0ms\n",
            "image 96/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame7200.png: 384x640 20 faces, 7.9ms\n",
            "image 97/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame8400.png: 384x640 24 faces, 7.9ms\n",
            "image 98/98 /content/drive/MyDrive/Deployment_Folders/Deployment_Final_30_10/vid2frame9600.png: 384x640 26 faces, 7.9ms\n",
            "Speed: 0.5ms pre-process, 8.4ms inference, 2.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recognition"
      ],
      "metadata": {
        "id": "cozgKQT7rcUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import csv"
      ],
      "metadata": {
        "id": "_RDzuGH_r27b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 43)\n",
        "model = model.to(device)\n",
        "\n",
        "# Load the saved weights\n",
        "saved_weights_path = \"/content/Recognition_Weights_224_Final.pt\"\n",
        "saved_weights = torch.load(saved_weights_path)\n",
        "model.load_state_dict(saved_weights)\n",
        "\n",
        "# Switch to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#transformations \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#image_dir is the directory that has the cropped images resulting from the detection model\n",
        "image_dir = \"/content/drive/MyDrive/Deployment_Folders/Deployment_CroppedFaces\"\n",
        "\n",
        "\n",
        "# Get a list of all image file paths in the directory\n",
        "image_paths = glob.glob(os.path.join(image_dir, \"*.jpg\"))\n",
        "\n",
        "# Create a list to store the predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "for path in image_paths:\n",
        "    #Open the image\n",
        "    image = Image.open(path)\n",
        "    \n",
        "    #transformations\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    \n",
        "    #make predictions\n",
        "    with torch.no_grad():\n",
        "        image = image.to(device)\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        predicted_labels.append(predicted.item())\n",
        "\n",
        "#Print the predicted labels\n",
        "num_to_name = {'abdelnasser abuziuter': 0, 'abdelrahman elayyan': 1, 'ahmad ghuneim': 2, 'aya ladadweh': 3, 'aya sulaq': 4, \n",
        "               'ban qaqish': 5, 'bana hjeji': 6, 'batool barakat': 7, 'christine amareen': 8, 'dana twal ': 9, 'fahd othman': 10, \n",
        "               'hashem thabsem': 11, 'jana shaer': 12, 'kholoud qubbaj': 13, 'lara diab': 14, 'malak abdelwahab': 15, 'mohammad jumaa': 16, \n",
        "               'noor alawi': 17, 'noor awwad': 18, 'osama zamel': 19, 'raghad abu tarboush': 20, 'rakan armoush': 21, 'rama al alawneh': 22, \n",
        "               'raneem nabulsea': 23, 'reem assi': 24, 'rose al nairab': 25, 'saif aburaisi': 26, 'saja taweel': 27, 'samira abubakr': 28, \n",
        "               'sanad abu khalaf': 29, 'sara darwish': 30, 'sara selwadi': 31, 'shahem al naber': 32, 'suhaib abu kiwan': 33, 'suheil wakileh': 34, \n",
        "               'tamara kawamleh': 35, 'tareq sarayji': 36, 'tariq sallam': 37, 'tasneem sanuri': 38, 'waleed abujaish': 39, 'yara matarneh': 40, \n",
        "               'yousef shaqadan': 41, 'zain shaarawi': 42}\n",
        "inverted_dict = {v: k for k, v in num_to_name.items()}\n",
        "students = num_to_name.keys()\n",
        "\n",
        "result = []\n",
        "for i in predicted_labels:\n",
        "    if predicted_labels.count(i) >= 1 and i not in result:\n",
        "        result.append(i)\n",
        "result_names = [inverted_dict[num] for num in result]\n",
        "print(result_names)\n",
        "\n",
        "attendance_dict = {student: 1 if student in result_names else 0 for student in students}\n",
        "\n",
        "# write attendance to CSV file\n",
        "with open('attendance.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Name', 'Attendance'])\n",
        "    for student in students:\n",
        "        writer.writerow([student, attendance_dict[student]])"
      ],
      "metadata": {
        "id": "80R0Wis_bryv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}